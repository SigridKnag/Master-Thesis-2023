{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ztWmkFD0EPES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdc420a-d951-4e2d-9983-bd6d965cedbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geemap in /usr/local/lib/python3.8/dist-packages (0.20.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from geemap) (1.21.6)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (from geemap) (4.4.0)\n",
            "Requirement already satisfied: whiteboxgui>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (2.2.0)\n",
            "Requirement already satisfied: ipywidgets<8.0.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (7.7.1)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.8/dist-packages (from geemap) (0.1.5)\n",
            "Requirement already satisfied: sankee>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.2.1)\n",
            "Requirement already satisfied: pyshp>=2.1.3 in /usr/local/lib/python3.8/dist-packages (from geemap) (2.3.1)\n",
            "Requirement already satisfied: earthengine-api>=0.1.304 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.1.341)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from geemap) (1.3.5)\n",
            "Requirement already satisfied: ipyfilechooser>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.6.0)\n",
            "Requirement already satisfied: pycrs in /usr/local/lib/python3.8/dist-packages (from geemap) (1.0.2)\n",
            "Requirement already satisfied: geocoder in /usr/local/lib/python3.8/dist-packages (from geemap) (1.38.1)\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.8/dist-packages (from geemap) (7.0.1)\n",
            "Requirement already satisfied: geeadd>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.5.6)\n",
            "Requirement already satisfied: pyperclip in /usr/local/lib/python3.8/dist-packages (from geemap) (1.8.2)\n",
            "Requirement already satisfied: eerepr>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.0.4)\n",
            "Requirement already satisfied: geojson in /usr/local/lib/python3.8/dist-packages (from geemap) (3.0.1)\n",
            "Requirement already satisfied: folium>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.12.1.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from geemap) (3.2.2)\n",
            "Requirement already satisfied: ee-extra>=0.0.10 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.0.15)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from geemap) (7.1.2)\n",
            "Requirement already satisfied: scooby in /usr/local/lib/python3.8/dist-packages (from geemap) (0.7.1)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.8/dist-packages (from geemap) (2023.2.0)\n",
            "Requirement already satisfied: ipyleaflet>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from geemap) (0.17.2)\n",
            "Requirement already satisfied: ipytree in /usr/local/lib/python3.8/dist-packages (from geemap) (0.2.2)\n",
            "Requirement already satisfied: ipyevents in /usr/local/lib/python3.8/dist-packages (from geemap) (2.0.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.8/dist-packages (from geemap) (0.2.0)\n",
            "Requirement already satisfied: bqplot in /usr/local/lib/python3.8/dist-packages (from geemap) (0.12.36)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (0.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (0.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (2.7.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (2.16.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.8/dist-packages (from earthengine-api>=0.1.304->geemap) (2.70.0)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from folium>=0.11.0->geemap) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from folium>=0.11.0->geemap) (2.11.3)\n",
            "Requirement already satisfied: logzero>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from geeadd>=0.5.1->geemap) (1.7.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in /usr/local/lib/python3.8/dist-packages (from geeadd>=0.5.1->geemap) (4.11.2)\n",
            "Requirement already satisfied: traittypes<3,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from ipyleaflet>=0.17.0->geemap) (0.2.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (5.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (3.0.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<8.0.0->geemap) (3.6.2)\n",
            "Requirement already satisfied: plotly>=5.2.2 in /usr/local/lib/python3.8/dist-packages (from sankee>=0.1.0->geemap) (5.5.0)\n",
            "Requirement already satisfied: whitebox in /usr/local/lib/python3.8/dist-packages (from whiteboxgui>=0.6.0->geemap) (2.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->geemap) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->geemap) (2.8.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python->geemap) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown->geemap) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown->geemap) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown->geemap) (3.9.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.8/dist-packages (from geocoder->geemap) (0.1.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from geocoder->geemap) (8.1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->geemap) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->geemap) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->geemap) (0.11.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4>=4.9.0->geeadd>=0.5.1->geemap) (2.4)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=0.1.304->geemap) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=0.1.304->geemap) (2.11.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.304->geemap) (0.2.8)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0->geemap) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0->geemap) (6.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9->folium>=0.11.0->geemap) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.2.2->sankee>=0.1.0->geemap) (8.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->earthengine-api>=0.1.304->geemap) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->earthengine-api>=0.1.304->geemap) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->earthengine-api>=0.1.304->geemap) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->earthengine-api>=0.1.304->geemap) (2.10)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (6.3.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage->earthengine-api>=0.1.304->geemap) (2.4.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage->earthengine-api>=0.1.304->geemap) (2.3.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->earthengine-api>=0.1.304->geemap) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=0.1.304->geemap) (1.58.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=0.1.304->geemap) (3.19.6)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->earthengine-api>=0.1.304->geemap) (1.5.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.8.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.16.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (5.2.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.13.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (5.7.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (21.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.2.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api>=0.1.304->geemap) (0.4.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets<8.0.0->geemap) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (3.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (21.2.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (6.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (5.10.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0.0->geemap) (3.13.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.8/dist-packages (0.12.2)\n",
            "Requirement already satisfied: pyproj>=2.6.1.post1 in /usr/local/lib/python3.8/dist-packages (from geopandas) (3.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from geopandas) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from geopandas) (23.0)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.8/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.8/dist-packages (from geopandas) (1.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (2022.12.7)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (8.1.3)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: munch>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (22.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch>=2.3.2->fiona>=1.8->geopandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install geemap        # --> Google Earth Engine (GEE)\n",
        "!pip install geopandas      #--> Geospatial data \n",
        "%pip install scikit-learn   #--> Machine learning \n",
        "\n",
        "# Talking with local terminal on your computer\n",
        "import os\n",
        "\n",
        "# GEE\n",
        "import ee\n",
        "from geemap.conversion import js_snippet_to_py\n",
        "import geemap\n",
        "from geemap import ml\n",
        "\n",
        "# Geospatial data manipulation and analysis tools\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "# Machine learning with sci-kit learn\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import (make_blobs,\n",
        "                              make_circles,\n",
        "                              make_moons)\n",
        "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which prorcessor unit we are using\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "Zbnu0bKfEhcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize access to GEE\n",
        "Map = geemap.Map()\n",
        "\n",
        "# 0) Follow external link \n",
        "# 1) Choose project name\n",
        "# 2) \"Generate token\"\n",
        "# 3) Choose account\n",
        "# 4) Give access (check of both boxes)\n",
        "# 5) Copy authorization code\n",
        "# 6) Add authorization code below"
      ],
      "metadata": {
        "id": "L2l-hgCCEjOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata on hardware, software etc. \n",
        "geemap.Report()"
      ],
      "metadata": {
        "id": "LcZo3-NyElNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a cloud-free Sentinel-2 composite (from raw imagery).\n",
        "# Source code: https://developers.google.com/earth-engine/guides/ic_info. Accessed: 16.02.2023\n",
        "\n",
        "point = ee.Geometry.Point([-69.740859, 43.544235]) # Center around a specified point\n",
        "\n",
        "image = (\n",
        "    ee.ImageCollection('COPERNICUS/S2_SR')         # Dataset from GEE\n",
        "    .filterBounds(point)                           # Filter satellite-images around our region of interest (ROI)\n",
        "    .filterDate('2019-06-02','2019-10-01')         # Filter time\n",
        "    .sort('CLOUDY_PIXEL_PERCENTAGE')               # fiter for cloud percentage\n",
        "    .first()                                       # Take the image with least cloud coverage\n",
        "    .select('B[2-4]','B[8]')                       # Select bands B2, B3, B4, and B8 as features\n",
        ")\n",
        "\n",
        "print('Date image was taken in the format YYYY-MM-DD:', ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()) # Show the image-date\n",
        "print('Cloud percentage: ', image.get('CLOUDY_PIXEL_PERCENTAGE').getInfo())"
      ],
      "metadata": {
        "id": "r0z8ris6ErPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image pre-pocessing\n",
        "\n",
        "##Sun-glint correction\n",
        "\n",
        "\n",
        "- Adaptation from https://www.youtube.com/watch?v=_V0X1LdSta4. Accessed 10.02.2023.\n",
        "- The python dicitonary needs ** in front of the dictionary in order pass keyword arguments into it. This does not go automatically with the 'js_snippet_to_py'. See https://realpython.com/python-kwargs-and-args/ for complete explenation. Accessed 16.02.2023. "
      ],
      "metadata": {
        "id": "rS9Sra-yExxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map.set_center(-69.740859, 43.544235, zoom=9)\n",
        "\n",
        "# Show sentinel-2 tile in map\n",
        "vis_params = {\"bands\": [ 'B2', 'B3', 'B4'], \"min\": 0, \"max\": 1500, \"gamma\": 1.5}\n",
        "Map.addLayer(image, vis_params, 'Sentinel-2 images')\n",
        "\n",
        "Map \n",
        "# Use toolbar on the left side, e.g., \" Draw a rectangle\" over a sight \n",
        "# to extract NIR values (min and random) from two pixels. \n",
        "# Areas of deep waters are recommended."
      ],
      "metadata": {
        "id": "tGmFcw-kE1x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map.draw_features                                # Collects the drawn rectangle(s)\n",
        "glint = ee.FeatureCollection(Map.draw_features)  # Stores the rectangle(s) geometry to extract NIR-values from\n",
        "\n",
        "def deglint(img):\n",
        "  '''\n",
        "  Sun-glint correction of image\n",
        "  '''\n",
        "  # Blue (B2) and NIR (B8) \n",
        "  # linearfitB gets linear relationship (slope) and offset between the Blue and NIR bands\n",
        "  linearfitB = img.select(['B8','B2']).reduceRegion(\n",
        "    **{\n",
        "    'reducer': ee.Reducer.linearFit(),  \n",
        "    'geometry': glint,\n",
        "    'scale':10,\n",
        "    'maxPixels':1e9\n",
        "    }) \n",
        "\n",
        "  # Green (B3) and NIR (B8)\n",
        "  # linearfitG gets linear relationship (slope) and offset between the Green and NIR bands  \n",
        "  linearfitG = img.select(['B8','B3']).reduceRegion(\n",
        "     **{\n",
        "      'reducer': ee.Reducer.linearFit(),\n",
        "      'geometry': glint,\n",
        "      'scale':10,\n",
        "      'maxPixels':1e9\n",
        "      })  \n",
        "  # Red and NIR\n",
        "  # linearfitR gets linear relationship (slope) and offset between the Red and NIR bands\n",
        "  linearfitR = img.select(['B8','B4']).reduceRegion(\n",
        "    **{\n",
        "      'reducer': ee.Reducer.linearFit(),\n",
        "      'geometry': glint,\n",
        "      'scale':10,\n",
        "      'maxPixels':1e9\n",
        "      })\n",
        "  \n",
        "  \n",
        "  slopeImage = ee.Dictionary(            # Collects the slopes in a dictionary \n",
        "  {\n",
        "      'Blue': linearfitB.get('scale'),\n",
        "      'Green': linearfitG.get('scale'),\n",
        "      'Red': linearfitR.get('scale')\n",
        "      }).toImage()                        # Converts dicitonary to image\n",
        "      \n",
        "  # Define minimum NIR value\n",
        "  minNIR = img.select('B8').reduceRegion(ee.Reducer.min(), glint).toImage()\n",
        "\n",
        "  # Deglint formula\n",
        "  return img.select(['B2','B3', 'B4']).subtract(slopeImage.multiply(img.select('B8').subtract(minNIR)))\n",
        "\n",
        "# Apply deglint function\n",
        "S2_deglint = deglint(image) \n",
        "\n",
        "# Might get a HttpError here stating: \n",
        "# \"Too many pixels in the region. Found 11099489, but maxPixels allows only 10000000.\"\n",
        "# The problem is that the rectangle created to extract NIR-values is too big. \n",
        "# Thus, create a new and smaller rectangle, or for future recommendations,\n",
        "# create a error-statement (using if-else) to where this is clearly explained or something similar. \n",
        "\n",
        "# Show deglinted image in map\n",
        "vis_params_deglint = {\"bands\": [ 'B2', 'B3','B4'], \"min\": 0, \"max\": 1500, 'gamma':1.5}\n",
        "\n",
        "Map.addLayer(S2_deglint, vis_params_deglint, 'sun-glint corrected Sent-2')\n",
        "Map"
      ],
      "metadata": {
        "id": "U07dJumRFEn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature collection for pixel-based classification (6 features)\n",
        "\n",
        "\n",
        "From the raw sentinel-2 tile, B2, B3, B4, and B8 were collected. For the pixel-based analysis we chose to collect the normalized difference vegetation index (NDVI) and bathymetry. In total 6 features. "
      ],
      "metadata": {
        "id": "JVNI13YXFYz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add NDVI-band to image"
      ],
      "metadata": {
        "id": "z5b1xfuPJ3K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating NDVI\n",
        "nir = image.select('B8')\n",
        "red = image.select('B4')\n",
        "ndvi_image = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "\n",
        "# Add NIR-band to deglinted image\n",
        "S2_deglint = S2_deglint.addBands(nir)\n",
        "\n",
        "# Add NDVI to RGB-image and deglinted image\n",
        "S2_deglint = S2_deglint.addBands(ndvi_image)\n",
        "image = image.addBands(ndvi_image)\n",
        "\n",
        "# sent2019 = ee.Image('COPERNICUS/S2/20190719T153601_20190719T153707_T19TDJ')"
      ],
      "metadata": {
        "id": "8npK5lp3FVQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add bathemerty band to image"
      ],
      "metadata": {
        "id": "vV6pfyO8J1ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map # Draw region of interest\n"
      ],
      "metadata": {
        "id": "yQYCf1BHJ7D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store geometry of region of interest in 'roi'\n",
        "roi = ee.FeatureCollection(Map.draw_last_feature)\n",
        "\n",
        "#Citations:\n",
        "# Amante, C. and B. W. Eakins, ETOPO1 1 Arc-Minute Global Relief Model: Procedures, Data Sources and Analysis. \n",
        "# NOAA Technical Memorandum NESDIS NGDC-24, 19 pp, March 2009.\n",
        "\n",
        "# Import elevation dataset from GEE\n",
        "dataset = ee.Image('NOAA/NGDC/ETOPO1')\n",
        "bathymetry_clipped = dataset.clip(roi)\n",
        "\n",
        "# Extract band 'bedrock' and rename it bathymetry for convenience\n",
        "bathymetry = bathymetry_clipped.select('bedrock').rename('bathymetry')\n",
        "\n",
        "# Set visualization parameters\n",
        "bathymetryVis = {\n",
        "  'min': -7000.0,\n",
        "  'max': 3000.0,\n",
        "  'palette': ['011de2', 'afafaf', '3603ff', 'fff477', 'b42109'],\n",
        "}\n",
        "\n",
        "# Add bathymetry band to deglinted and raw image\n",
        "S2_deglint = S2_deglint.addBands(bathymetry)\n",
        "image = image.addBands(bathymetry)\n",
        "\n",
        "S2_deglint.bandNames()\n",
        "# Add NDVI-image to map\n",
        "#ndviParams = {min: -1, max: 1, 'palette': ['blue', 'white', 'green']}\n",
        "#Map.addLayer(ndvi_image, ndviParams, 'NDVI image')\n",
        "# Add bathymetry data on the map\n",
        "#Map.addLayer(bathymetry, bathymetryVis, 'bathymetry')"
      ],
      "metadata": {
        "id": "IOMN0H-rJ-4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature collection for Object-based image analysis classification (11 features).\n",
        "\n",
        "For the OBIA 5 additional feautres are added to the dataset used to classify seagrass from seaweed. These are obtained by creating super-pixels and then extracting their characteristics. That is: area, clusters, height, perimeter, and width. "
      ],
      "metadata": {
        "id": "kgaql19iMDCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Create super-pixels with SNIC"
      ],
      "metadata": {
        "id": "Xo-_82K-Nq-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select seed-pixels for clustering, spaced at least 36 pixels apart. Clipped to region of interest.  \n",
        "seeds = ee.Algorithms.Image.Segmentation.seedGrid(36).clip(roi)\n",
        "\n",
        "# Run SNIC\n",
        "snic = ee.Algorithms.Image.Segmentation.SNIC(**{\n",
        "  'image': S2_deglint,                               \n",
        "  'size': 32,                                      # \n",
        "  'compactness': 5,\n",
        "  'connectivity': 8,\n",
        "  'neighborhoodSize':256,\n",
        "  'seeds': seeds\n",
        "}).select(['B2_mean', 'B3_mean', 'B4_mean', 'B8_mean','clusters', 'bathymetry_mean','NDVI_mean'], ['B', 'G', 'R','NIR', 'clusters', 'bathymetry','NDVI'])\n",
        "\n",
        "# source code: https://gis.stackexchange.com/questions/333413/is-google-earth-engine-snic-segmentation-algorithm-inconsistent. Accessed 10.02.23\n",
        "snic.reproject(**{\n",
        "  'crs': 'EPSG:4326',\n",
        "  'scale': 10\n",
        "})\n",
        "\n",
        "# Source code: https://developers.google.com/earth-engine/apidocs/ee-algorithms-image-segmentation-snic. 10.02.23\n",
        "# Lock map zoom to maintain the desired scale of the segmentation computation.\n",
        "\n",
        "#Display the clusters.\n",
        "#Map.addLayer(snic.randomVisualizer(), None, 'Clusters')\n",
        "# Display the RGB cluster means.\n",
        "visParams = {\n",
        "  'bands': ['R', 'G', 'B'],\n",
        "  'min': 0,\n",
        "  'max': 255\n",
        "}\n",
        "#Map.addLayer(snic, visParams, 'RGB cluster means')\n",
        "\n",
        "# Compute per-cluster stdDev.\n",
        "clusters = snic.select('clusters')    # image.addBands(clusters) or S2_deglint.addBands(clusters)\n",
        "stdDev = S2_deglint.addBands(clusters).reduceConnectedComponents(ee.Reducer.stdDev(), 'clusters', 256)\n",
        "#Map.addLayer(stdDev, {min:0, max:0.1}, 'StdDev', False)\n",
        "\n",
        "#Area\n",
        "area = ee.Image.pixelArea().addBands(clusters).reduceConnectedComponents(ee.Reducer.sum(), 'clusters', 256)\n",
        "#Map.addLayer(area, {min:50000, max: 500000}, 'Cluster Area', False)\n",
        "\n",
        "minMax = clusters.reduceNeighborhood(ee.Reducer.minMax(), ee.Kernel.square(1))\n",
        "perimeterPixels = minMax.select(0).neq(minMax.select(1)).rename('perimeter')\n",
        "#Map.addLayer(perimeterPixels, {min: 0, max: 1}, 'perimeterPixels')\n",
        "\n",
        "# Perimeter\n",
        "perimeter = perimeterPixels.addBands(clusters).reduceConnectedComponents(ee.Reducer.sum(), 'clusters', 256);\n",
        "#Map.addLayer(perimeter, {min: 100, max: 400}, 'Perimeter size', False);\n",
        "\n",
        "# Width and Height\n",
        "sizes = ee.Image.pixelLonLat().addBands(clusters).reduceConnectedComponents(ee.Reducer.minMax(), 'clusters', 256)\n",
        "width = sizes.select('longitude_max').subtract(sizes.select('longitude_min')).rename('width')\n",
        "height = sizes.select('latitude_max').subtract(sizes.select('latitude_min')).rename('height')\n",
        "#Map.addLayer(width, {min:0, max:0.02}, 'Cluster width', False)\n",
        "#Map.addLayer(height, {min:0, max:0.02}, 'Cluster height', False)\n",
        "\n",
        "bands = ['R', 'G', 'B', 'NIR','clusters','bathymetry','NDVI']\n",
        "\n",
        "# objectPropertiesImage is now an image containing 11 feautres.  \n",
        "objectPropertiesImage = ee.Image.cat([\n",
        "  snic.select(bands),\n",
        "  stdDev,\n",
        "  area,\n",
        "  perimeter,\n",
        "  width,\n",
        "  height\n",
        "]).float()"
      ],
      "metadata": {
        "id": "EzbyR7vRNqxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sample data (11 features)"
      ],
      "metadata": {
        "id": "Q_3AZCMBP2dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Use functions below if data to get sample data fro training, validaiton and test. \n",
        "# To save time, these sets have already been created and stored locally.\n",
        "# The files used her ecan be found with the rest on git-hub for reproducable results.\n",
        "\n",
        "# increase sample size of seaweed\n",
        "sample_sw = objectPropertiesImage.sample(**{\n",
        "  'region': seaweed_shp,\n",
        "  'numPixels':26000,  # As it does not collect clsoe to 5000 samples when set to this, we increase this value. Should be adjusted if error is thrown.\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,   # Set to 10 as our resolution is 10-meters\n",
        "})\n",
        "\n",
        "sample_sg = objectPropertiesImage.sample(**{\n",
        "  'region': seagrass_shp,\n",
        "  'numPixels':5000,   # 5000 pixels is the maximum number of pixels that can be processed in GEE\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,\n",
        "})\n",
        "\n",
        "sample_water = objectPropertiesImage.sample(**{\n",
        "  'region': water_shp.geometry(),\n",
        "  'numPixels':5000,\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,\n",
        "})\n",
        "\n",
        "#Code to display sample-points if needed\n",
        "\n",
        "\n",
        "Map.addLayer(sample_sg, vis_params_sg, 'seagrass samples')\n",
        "Map.addLayer(sample_sw, vis_params_sw, 'seaweed samples')\n",
        "Map.addLayer(sample_water, vis_params_water, 'water samples')\n",
        "Map\n",
        "\n",
        "# Convert samples from ee-objects to geodataframes\n",
        "gdf_sw = geemap.ee_to_geopandas(sample_sw)\n",
        "gdf_sg = geemap.ee_to_geopandas(sample_sg)\n",
        "gdf_water = geemap.ee_to_geopandas(sample_water)\n",
        "\n",
        "# Get number of samples fetched for each class\n",
        "length_sg = len(gdf_sg)\n",
        "length_sw = len(gdf_sw)\n",
        "length_water = len(gdf_water)\n",
        "print(f'We have: \\n {length_sg} samples from the seagrass polygons \\n {length_sw} samples from the seaweed polygons \\n {length_water} samples from the water polygons ')\n",
        "\n",
        " # Crete Class column 'Cover'\n",
        "gdf_water['Cover'] =  int(1) # class water\n",
        "gdf_sw['Cover'] =  int(2)    # class seaweed\n",
        "gdf_sg['Cover'] =  int(3)    # class seagrass\n",
        "\n",
        "\n",
        "# Merge the three dataframes and create a single dataset\n",
        "# Source code: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html. Accessed 08.02.23\n",
        "frames = [gdf_water, gdf_sw, gdf_sg]\n",
        "\n",
        "data = pd.concat(frames, ignore_index=True)\n",
        "print(len(data))\n",
        "'''"
      ],
      "metadata": {
        "id": "4Cj7Ro26L3Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pixel-based (7 feautres) classification\n",
        "\n",
        "- 1) Import geometries to fetch samples from\n",
        "- 2) Sample data\n",
        "- 3) Locally store data for faster processing for next time as well as reproducability\n"
      ],
      "metadata": {
        "id": "E8AwKggIKy1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import geometries to fetch samples from"
      ],
      "metadata": {
        "id": "I4F9V4gMLA-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add ground truth data geometry of seagrass and seaweed\n",
        "# Must upload to google colabs for each new runtime...\n",
        "shp_path_SW = '/content/try1.shp'\n",
        "seaweed_shp = geemap.shp_to_ee(shp_path_SW)\n",
        "\n",
        "shp_path_SG = '/content/MaineDEP_-_Eelgrass_2018_(Casco_Bay_Only).shp'\n",
        "seagrass_shp = geemap.shp_to_ee(shp_path_SG)\n",
        "\n",
        "# Drew rectangles to represent water, than dowloaded them locally\n",
        "# geemap.ee_to_shp(water, filename='/content/water.shp')\n",
        "shp_path_water = '/content/water.shp'\n",
        "water_shp = geemap.shp_to_ee(shp_path_water)\n"
      ],
      "metadata": {
        "id": "ix4J5HJuKx5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample data (7 features)"
      ],
      "metadata": {
        "id": "PDQCnntWLHYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use functions below if data to get sample data fro training, validaiton and test. \n",
        "# To save time, these sets have already been created and stored locally.\n",
        "# The files used her ecan be found with the rest on git-hub for reproducable results.\n",
        "\n",
        "'''\n",
        "# Samples of seaweed\n",
        "sample_sw = S2_deglint.sample(**{\n",
        "  'region': seaweed_shp,\n",
        "  'numPixels':25000, # As it does not collect clsoe to 5000 samples when set to this, we increase this value. Should be adjusted if error is thrown.\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,      # Set to 10 as our resolution is 10-meters    \n",
        "})\n",
        "\n",
        "# Samples of seagrass\n",
        "sample_sg = S2_deglint.sample(**{\n",
        "  'region': seagrass_shp,\n",
        "  'numPixels':5000,  # 5000 pixels is the maximum number of pixels that can be processed in GEE\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,\n",
        "})\n",
        "\n",
        "# Sample of water\n",
        "sample_water = S2_deglint.sample(**{\n",
        "  'region': water_shp,\n",
        "  'numPixels':5000,\n",
        "  'geometries': True,\n",
        "  'seed' :3,\n",
        "  'scale': 10,\n",
        "})\n",
        "\n",
        "\n",
        "# Code to display sample-points if needed\n",
        "Map.addLayer(sample_sg, vis_params_sg, 'seagrass samples')\n",
        "Map.addLayer(sample_sw, vis_params_sw, 'seaweed samples')\n",
        "Map.addLayer(sample_water, vis_params_water, 'water samples')\n",
        "\n",
        "Map\n",
        "\n",
        "# Convert samples from ee-objects to geodataframes\n",
        "gdf_sw = geemap.ee_to_geopandas(sample_sw)\n",
        "gdf_sg = geemap.ee_to_geopandas(sample_sg)\n",
        "gdf_water = geemap.ee_to_geopandas(sample_water)\n",
        "\n",
        "\n",
        "# Get number of samples fetched for each class\n",
        "length_sg = len(gdf_sg)\n",
        "length_sw = len(gdf_sw)\n",
        "length_water = len(gdf_water)\n",
        "print(f'We have: \\n {length_sg} samples from the seagrass polygons \\n {length_sw} samples from the seaweed polygons \\n {length_water} samples from the water polygons ')\n",
        "\n",
        " # Crete Class column 'Cover'\n",
        "gdf_water['Cover'] =  int(1) # class water\n",
        "gdf_sw['Cover'] =  int(2)    # class seaweed\n",
        "gdf_sg['Cover'] =  int(3)    # class seagrass\n",
        "\n",
        "\n",
        "# Merge the three dataframes and create a single dataset\n",
        "# Source code: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html. Accessed 08.02.23\n",
        "frames = [gdf_water, gdf_sw, gdf_sg]\n",
        "\n",
        "data = pd.concat(frames, ignore_index=True)\n",
        "print(len(data))\n",
        "'''"
      ],
      "metadata": {
        "id": "hEMKQN1JLIpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Locally store data for faster processing for next time as well as reproducability"
      ],
      "metadata": {
        "id": "yBWT18peLTyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to locally store sample data:\n",
        "\n",
        "# All data: \n",
        "# 1) data = data.drop('geometry', axis=1)\n",
        "# 2) data.to_csv(r'/content/data_pixel_based_UML_23.csv', index=False)'\n",
        "\n",
        "# Only training data:\n",
        "# 1) data = data.sample(frac=1)\n",
        "# 2) train = data.drop(['geometry','Cover'], axis=1)\n",
        "# 3) train.to_csv(r'/content/train_pixel_based_UML_23.csv', index=False)\n",
        "\n",
        "# Only class data:\n",
        "# 1) y_true = data['Cover']\n",
        "# 2) y_true.to_csv(r'/content/ytrue_pixel_based_UML_23.csv', index=False)\n",
        "\n",
        "# Access locally stored data: \n",
        "# 1) Upload files to session storage\n",
        "# 2) Choose training and classs data seperatly:\n",
        "df = pd.read_csv('/content/train_pixel_based_UML_23.csv')\n",
        "y_true_df = pd.read_csv('/content/ytrue_pixel_based_UML_23.csv')\n",
        "data7 = pd.read_csv('/content/data_pixel_based_UML_23.csv')\n",
        "\n",
        "df.columns\n",
        "#data.isnull().sum().sum() # Check null-values, in which case must be removed.\n",
        "\n",
        "# LOCALLY STORING PROCESS FOR OBIA\n",
        "'''\n",
        "# How to locally store sample data:\n",
        "\n",
        "# All data: \n",
        "# 1) data.head()               # Check how the data looks \n",
        "# 2) data.isnull().sum().sum() # Check for null-values \n",
        "# 3) data.columns              # Found mix-up mistake of columns\n",
        "# 4) data = data.drop(['geometry','B', 'G', 'NDVI_1', 'NIR',\n",
        "#       'R', 'bathymetry_1'], axis=1) # fixed mistake \n",
        "# 5) data.head()                # Verify that our fix worked\n",
        "# 6) data = data.sample(frac=1) # Randomize the data\n",
        "# 7) data.to_csv(r'/content/data_OBIA_MT23.csv', index=False)\n",
        "\n",
        "# Only training data:\n",
        "# 1) train = data.drop(['Cover'], axis=1)\n",
        "# 2) train.to_csv(r'/content/train_OBIA_MT23.csv', index=False)\n",
        "\n",
        "# Only class data:\n",
        "# 3) y_true = data['Cover']\n",
        "# 4) y_true.to_csv(r'/content/ytrue_OBIA_MT23.csv', index=False)\n",
        "\n",
        "# Access locally stored data: \n",
        "# 1) Upload files to session storage\n",
        "# 2) Choose training and classs data seperatly:\n",
        "df = pd.read_csv('/content/train_OBIA_MT23.csv')\n",
        "y_true_df = pd.read_csv('/content/ytrue_OBIA_MT23.csv')\n",
        "data11 = pd.read_csv('/content/data_OBIA_MT23.csv')\n",
        "\n",
        "df.head()\n",
        "'''"
      ],
      "metadata": {
        "id": "ojC6g5dFLWfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load datasets \n",
        "\n",
        "# Data with 11 feautres \n",
        "#data11 = pd.read_csv('/content/data_OBIA_MT23.csv')\n",
        "\n",
        "# Data with 7 feautres \n",
        "data7 = pd.read_csv('/content/data_pixel_based_UML_23.csv')\n",
        "\n",
        "# Data with 3 feautres \n",
        "data3 = data7.loc[:,['B2','B3','B4','Cover']]"
      ],
      "metadata": {
        "id": "HBViyFx8O6dG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data3.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R5f4diQWjg8",
        "outputId": "9eff4e35-c041-4f31-95b3-5f7cd0e57912"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Standardize the data \n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "# Training dataset set to 80 %\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X_std, y, train_size=0.8, random_state=42)\n",
        "# Validation and test dataset set to 10% each\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "e9GrPbIIQTqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Supervised - Random Forest (RF)"
      ],
      "metadata": {
        "id": "N2wj1uAdSESh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_RF(data):\n",
        "  '''\n",
        "  Takes any dataset with X feautres and a column of y-values in.\n",
        "  Function assumes the last column to contain the class-labels of the data\n",
        "  '''\n",
        "  y = data.iloc[:,-1]  # Get class lables\n",
        "  label = y.name       # Get the name of class label\n",
        "  X = data.drop(label, axis = 1) # Get only feaures \n",
        "  y=y.astype('int')  # y was firstly of type 'object', needs to be an integer for sklearn to recognize it.\n",
        "\n",
        "\n",
        "  # Standardize the data \n",
        "  X_std = StandardScaler().fit_transform(X)\n",
        "  # Training dataset set to 80 %\n",
        "  X_train, X_rem, y_train, y_rem = train_test_split(X_std, y, train_size=0.8, random_state=42)\n",
        "  # Validation and test dataset set to 10% each\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)\n",
        "\n",
        "  rfc=RandomForestClassifier(random_state=42)\n",
        "\n",
        "  param_grid = {'n_estimators':[int(x) for x in np.linspace(start=10, stop = 30, num = 5)],\n",
        "              'max_features': ['sqrt', 'log2', None],\n",
        "              'max_depth':[2,4,10],\n",
        "              'min_samples_split': [2,5],\n",
        "              'min_samples_leaf':[1,2],\n",
        "              'bootstrap':[True, False]}\n",
        "\n",
        "  CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "  CV_rfc.fit(X_train, y_train)\n",
        "  dict_bp = CV_rfc.best_params_\n",
        "  rf = ensemble.RandomForestClassifier(n_estimators=dict_bp['n_estimators'],\n",
        "                                     max_depth=dict_bp['max_depth'],\n",
        "                                     min_samples_split=dict_bp['min_samples_split'],\n",
        "                                     min_samples_leaf=dict_bp['min_samples_leaf'],\n",
        "                                     max_features=dict_bp['max_features'],\n",
        "                                     bootstrap=dict_bp['bootstrap'],\n",
        "                                     n_jobs=-1,\n",
        "                                     random_state=3).fit(X_train, y_train)\n",
        "\n",
        "  preds = rf.predict(X_valid)\n",
        "  return accuracy_score(preds, y_valid), len(X.columns)\n"
      ],
      "metadata": {
        "id": "eRi6VCreSKpk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "results = supervised_RF(data3)  \n",
        "print(\"Oerall accuracy obtained by RF with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "print('Supervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVU4ogIPOxvG",
        "outputId": "ae7448ab-0098-4921-f101-4c690368db00"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by RF with 3 features is: 75.49%\n",
            "Supervised classificaiotn with 3 features completed in: 6.41 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets \n",
        "\n",
        "# Data with 11 feautres \n",
        "data11 = pd.read_csv('/content/data_OBIA_MT23.csv')\n",
        "\n",
        "# Data with 7 feautres \n",
        "data7 = pd.read_csv('/content/data_pixel_based_UML_23.csv')\n",
        "\n",
        "# Data with 3 feautres \n",
        "data3 = data7.loc[:,['B2','B3','B4','Cover']]\n",
        "\n"
      ],
      "metadata": {
        "id": "6bTJN7SgMshm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over data with different numbers of feautres\n",
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = supervised_RF(j)\n",
        "  print(\"Oerall accuracy obtained by RF with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Supervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "uVTyMpCHrhtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unsupervised(data, pca= True, algorithm = \" \"):\n",
        "  y = data.iloc[:,-1]  # Get class lables\n",
        "  label = y.name       # Get the name of class label\n",
        "  X = data.drop(label, axis = 1) # Get only feaures \n",
        "  y=y.astype('int')  # y was firstly of type 'object', needs to be an integer for sklearn to recognize it.\n",
        "  X_std = StandardScaler().fit_transform(X)\n",
        "\n",
        "  if pca == True:\n",
        "      pca = PCA(n_components = 2)\n",
        "      X_pca = pca.fit(X_std)\n",
        "      X_trans_pca = pca.transform(X_std)\n",
        "\n",
        "      if algorithm == 'kMeans':\n",
        "        km = KMeans(n_clusters=3, max_iter=100, random_state=40)\n",
        "        km.fit(X_trans_pca)\n",
        "        y_pred = km.labels_\n",
        "      else:\n",
        "        db = DBSCAN(eps=0.2, min_samples = 5, metric='euclidean')\n",
        "        db_fit = db.fit_predict(X_trans_pca)\n",
        "        y_pred = db.labels_\n",
        "      \n",
        "  else:\n",
        "    if algorithm == 'kMeans':\n",
        "        km = KMeans(n_clusters=3, max_iter=100, random_state=40)\n",
        "        km.fit(X_std)\n",
        "        y_pred = km.labels_ # Store predicted class for each point\n",
        "    else:\n",
        "        db = DBSCAN(eps=0.2, min_samples = 5, metric='euclidean')\n",
        "        db_fit = db.fit_predict(X_std)\n",
        "        y_pred = db.labels_\n",
        "\n",
        "  return accuracy_score(y, y_pred), len(X.columns)"
      ],
      "metadata": {
        "id": "6Xw1bttwmut6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = unsupervised(j, False, 'kMeans')\n",
        "  #print(f'Results {j} \\n' )\n",
        "  print(\"Oerall accuracy obtained by Kmeans with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Unupervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5itSFpENozmk",
        "outputId": "ffe6951f-71d8-4d0b-ba15-6e8829912211"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by Kmeans with 11 features is: 4.83%\n",
            "Unupervised classificaiotn with 11 features completed in: 0.02 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by Kmeans with 6 features is: 8.87%\n",
            "Unupervised classificaiotn with 6 features completed in: 0.01 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by Kmeans with 3 features is: 0.36%\n",
            "Unupervised classificaiotn with 3 features completed in: 0.00 minutes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = unsupervised(j, True, 'kMeans')\n",
        "  #print(f'Results {j} \\n' )\n",
        "  print(\"Oerall accuracy obtained by Kmeans using 2 PCA components with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Unupervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIYynBQFrDzh",
        "outputId": "0aec6fed-fb41-48e6-fc8e-664e65619d9f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by Kmeans using 2 PCA components with 11 features is: 21.55%\n",
            "Unupervised classificaiotn with 11 features completed in: 0.01 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by Kmeans using 2 PCA components with 6 features is: 30.16%\n",
            "Unupervised classificaiotn with 6 features completed in: 0.01 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by Kmeans using 2 PCA components with 3 features is: 0.35%\n",
            "Unupervised classificaiotn with 3 features completed in: 0.02 minutes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = unsupervised(j, True, 'DBSCAN')\n",
        "  #print(f'Results {j} \\n' )\n",
        "  print(\"Oerall accuracy obtained by DBSCAN using 2 PCA components with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Unupervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcVePwI4s-Dm",
        "outputId": "a9d31ce4-3332-425b-8dbf-4575db48b692"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by DBSCAN using 2 PCA components with 11 features is: 0.24%\n",
            "Unupervised classificaiotn with 11 features completed in: 0.00 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN using 2 PCA components with 6 features is: 0.00%\n",
            "Unupervised classificaiotn with 6 features completed in: 0.01 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN using 2 PCA components with 3 features is: 0.00%\n",
            "Unupervised classificaiotn with 3 features completed in: 0.01 minutes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = unsupervised(j, False, 'DBSCAN')\n",
        "  #print(f'Results {j} \\n' )\n",
        "  print(\"Oerall accuracy obtained by DBSCAN with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Unupervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVemCqc5tFLA",
        "outputId": "0249c12e-9b67-47b8-8363-427abcb1448c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by DBSCAN with 11 features is: 0.34%\n",
            "Unupervised classificaiotn with 11 features completed in: 0.02 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN with 6 features is: 0.62%\n",
            "Unupervised classificaiotn with 6 features completed in: 0.01 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN with 3 features is: 0.01%\n",
            "Unupervised classificaiotn with 3 features completed in: 0.01 minutes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semiSupervised(data):\n",
        "  y = data.iloc[:,-1]  # Get class lables\n",
        "  label = y.name       # Get the name of class label\n",
        "  X = data.drop(label, axis = 1) # Get only feaures \n",
        "  y=y.astype('int')  # y was firstly of type 'object', needs to be an integer for sklearn to recognize it.\n",
        "  X_std = StandardScaler().fit_transform(X)\n",
        "\n",
        "  # Firstly, the dataset is split into a unlabeled and a remaining datasets\n",
        "  # X_unlabled is 80% of the total dataset\n",
        "  X_unlabled, X_rem, y_unlabled, y_rem = train_test_split(X_std, y, train_size=0.8, random_state=42)\n",
        "\n",
        "  # Then, the remaining data is split into a labeled and a test dataset. \n",
        "  # we have to define valid_size=0.5 (that is 50% of remaining data)\n",
        "  # The labled and test datasets each conaints 10% of the samples from the total data \n",
        "\n",
        "  test_size = 0.5\n",
        "  X_labeled, X_test, y_labeled, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "  # Create a training and validation data from the labled data\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X_labeled,y_labeled, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "\n",
        "  # Initialize classifier\n",
        "  rfc=RandomForestClassifier(random_state=42)\n",
        "  param_grid = {'n_estimators':[int(x) for x in np.linspace(start=10, stop = 30, num = 5)],\n",
        "              'max_features': ['sqrt', 'log2', None],\n",
        "              'max_depth':[2,4,10],\n",
        "              'min_samples_split': [2,5],\n",
        "              'min_samples_leaf':[1,2],\n",
        "              'bootstrap':[True, False]}\n",
        "\n",
        "  CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "  CV_rfc.fit(X_train, y_train)\n",
        "  dict_bp = CV_rfc.best_params_\n",
        "  rf = ensemble.RandomForestClassifier(n_estimators=dict_bp['n_estimators'],\n",
        "                                     max_depth=dict_bp['max_depth'],\n",
        "                                     min_samples_split=dict_bp['min_samples_split'],\n",
        "                                     min_samples_leaf=dict_bp['min_samples_leaf'],\n",
        "                                     max_features=dict_bp['max_features'],\n",
        "                                     bootstrap=dict_bp['bootstrap'],\n",
        "                                     n_jobs=-1,\n",
        "                                     random_state=3).fit(X_train, y_train)\n",
        "\n",
        "  preds = rf.predict(X_unlabled)\n",
        "\n",
        "  # Merge dataset containing the labels\n",
        "  y_pseudo = np.append(preds, y_train)\n",
        "\n",
        "  # Merge dataset containing samples \n",
        "  pseudo_data = np.append(X_unlabled, X_train, axis=0)\n",
        "\n",
        "  rf = ensemble.RandomForestClassifier(n_estimators=dict_bp['n_estimators'],\n",
        "                                     max_depth=dict_bp['max_depth'],\n",
        "                                     min_samples_split=dict_bp['min_samples_split'],\n",
        "                                     min_samples_leaf=dict_bp['min_samples_leaf'],\n",
        "                                     max_features=dict_bp['max_features'],\n",
        "                                     bootstrap=dict_bp['bootstrap'],\n",
        "                                     n_jobs=-1,\n",
        "                                     random_state=3).fit(pseudo_data, y_pseudo)\n",
        "\n",
        "  preds_pseudo = rf.predict(X_test)\n",
        "  return accuracy_score(preds_pseudo, y_test), len(X.columns)\n",
        "\n",
        "for j in [data11, data7, data3]:\n",
        "  start_time = time.time()\n",
        "  results = semiSupervised(j)\n",
        "  #print(f'Results {j} \\n' )\n",
        "  print(\"Oerall accuracy obtained semisupervised model using RF with {} features is: {:.2f}%\".format(results[1], (results[0]*100)))\n",
        "  print('Unupervised classificaiotn with {} features completed in: {:.2f} minutes'.format(results[1],((time.time() - start_time)/60)))\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylddpjKCtNFW",
        "outputId": "f0f0ea1c-3361-4172-f02a-4252014cd3e2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oerall accuracy obtained by DBSCAN with 11 features is: 93.15%\n",
            "Unupervised classificaiotn with 11 features completed in: 1.19 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN with 6 features is: 89.86%\n",
            "Unupervised classificaiotn with 6 features completed in: 1.02 minutes\n",
            "\n",
            "\n",
            "Oerall accuracy obtained by DBSCAN with 3 features is: 70.72%\n",
            "Unupervised classificaiotn with 3 features completed in: 0.92 minutes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1ec0WUxvP2T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}